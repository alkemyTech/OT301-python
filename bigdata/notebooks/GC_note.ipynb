{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigData - StackOverflow\n",
    "\n",
    "### MapReduce- Group C\n",
    "\n",
    " As Data Analysts, we were in charge of proccessing and executing data to obtain the following requirements:\n",
    "\n",
    "  * Top 10 posts type with more accepted answers. \n",
    "\n",
    "  * Top 10 users with the most percentage of favorite answers.\n",
    "\n",
    "  * Relationship in between quantity of words in a post, and amount of answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First requirement: Top 10 posts type with more accepted answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''In this first case, we followed a different path to get some answers, by choosing \n",
    "different attributes. The reason was that the main attribute we were looking for, which was AcceptedAnswersId,\n",
    "as the name says, was an ID, and we were looing for an accounting attribute. That's why we chose AnswerCount\n",
    "to get some responses to what we were looking for.'''\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from functools import reduce\n",
    "from typing import Counter\n",
    "import re\n",
    "import operator\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def chunckify(iterable, len_of_chunk):\n",
    "    for i in range(0, len(iterable), len_of_chunk):\n",
    "        yield iterable[i:i + len_of_chunk]\n",
    "\n",
    "\n",
    "def obtener_cantidad_respuestas(data):\n",
    "    \n",
    "    id= data.attrib['Id']\n",
    "    try:\n",
    "        respuestas= data.attrib['AnswerCount']\n",
    "    except:\n",
    "        return\n",
    "    diccionario = {id: respuestas}\n",
    "    return diccionario\n",
    "\n",
    "\n",
    "\n",
    "def reducir_contadores(data1, data2):\n",
    "    for key, value in data2.items():\n",
    "        if key in data1.keys():\n",
    "            data1[key].update(data2[key])\n",
    "        else:\n",
    "            data1.update({key:value})\n",
    "    return data1    \n",
    "    \n",
    "    \n",
    "\n",
    "def mapper(data):\n",
    "    palabras_mapeadas= list(map(obtener_cantidad_respuestas, data))\n",
    "    palabras_mapeadas= list(filter(None, palabras_mapeadas))\n",
    "    try:\n",
    "        reductor= reduce(reducir_contadores, palabras_mapeadas)\n",
    "    except:\n",
    "        return \n",
    "    return reductor    \n",
    "    \n",
    "\n",
    "\n",
    "def calcular_top_10(data):\n",
    "    data=dict(data)\n",
    "    sorting= sorted(data.items(), key=operator.itemgetter(1), reverse= True)\n",
    "    list_s= []\n",
    "    for n in range(10):\n",
    "        list_s.append(sorting[n])\n",
    "    return dict(list_s)\n",
    "\n",
    "\n",
    "tree= ET.parse(r'/home/fer/OT301-python/Stack Overflow 11-2010/112010 Meta Stack Overflow/posts.xml')\n",
    "root= tree.getroot()\n",
    "data_chunks= chunckify(root, 50)\n",
    "mapped= list(map(mapper, data_chunks))\n",
    "mapped= list(filter(None, mapped))\n",
    "reduced= reduce(reducir_contadores, mapped)\n",
    "top_10= calcular_top_10(reduced)\n",
    "\n",
    "#print(top_10)\n",
    "\n",
    "#In order to execute the script, remove the # before the print function above.\n",
    "\n",
    "\n",
    "#The following lines we'll get the .txt with the requirements needed, in order to be read.\n",
    "with open(('/home/fer/OT301-python/bigdata/outputs/GC_r1.txt'), 'w') as f:\n",
    "        f.write(str(top_10))                   \n",
    "        f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post_Id</th>\n",
       "      <th>AnswerCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>810</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137077</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133260</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>133875</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13018</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131377</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>133733</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2644</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>139547</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>146097</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Post_Id AnswerCount\n",
       "0     810           9\n",
       "1  137077           9\n",
       "2  133260           9\n",
       "3  133875           9\n",
       "4   13018           8\n",
       "5  131377           8\n",
       "6  133733           8\n",
       "7    2644           8\n",
       "8  139547           8\n",
       "9  146097           8"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(('/home/fer/OT301-python/bigdata/outputs/GC_r1.csv'), 'w') as f:\n",
    "        f.write(str(top_10))\n",
    "        f.close()\n",
    "\n",
    "\n",
    "df = pd.DataFrame(top_10.items(), columns=['Post_Id', 'AnswerCount'])\n",
    "df.to_csv('/home/fer/OT301-python/bigdata/outputs/GC_r1.csv', index=False)\n",
    "df\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second requirement: Top 10 users with the most percentage of favorite answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from functools import reduce\n",
    "from typing import Counter\n",
    "import re\n",
    "import operator\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def chunckify(iterable, len_of_chunk):\n",
    "    for i in range(0, len(iterable), len_of_chunk):\n",
    "        yield iterable[i:i + len_of_chunk]\n",
    "\n",
    "\n",
    "def obtener_cantidad_usuarios(data):\n",
    "    try:\n",
    "        owner_id= data.attrib['OwnerUserId']\n",
    "    except:\n",
    "        return\n",
    "    try:\n",
    "        respuestas_fav= data.attrib['FavoriteCount']\n",
    "    except:\n",
    "        return\n",
    "    diccionario = {owner_id: respuestas_fav}\n",
    "    return diccionario\n",
    "\n",
    "\n",
    "\n",
    "def reducir_contadores(data1, data2):\n",
    "    for value in data2.items():\n",
    "        if value != 0:\n",
    "            data1.update(data2)\n",
    "        elif 0 in data1.values():\n",
    "            data1.popitem()\n",
    "    return data1\n",
    "        \n",
    "        \n",
    "\n",
    "def mapper(data):\n",
    "    palabras_mapeadas= list(map(obtener_cantidad_usuarios, data))\n",
    "    palabras_mapeadas= list(filter(None, palabras_mapeadas))\n",
    "    try:\n",
    "        reductor= reduce(reducir_contadores, palabras_mapeadas)\n",
    "    except:\n",
    "        return \n",
    "    return reductor    \n",
    "    \n",
    "\n",
    "\n",
    "def calcular_top_10(data):\n",
    "    data=dict(data)\n",
    "    sorting= sorted(data.items(), key=operator.itemgetter(1), reverse= True)\n",
    "    list_s= []\n",
    "    for n in range(10):\n",
    "        list_s.append(sorting[n])\n",
    "    return dict(list_s)\n",
    "\n",
    "\n",
    "tree= ET.parse(r'/home/fer/OT301-python/Stack Overflow 11-2010/112010 Meta Stack Overflow/posts.xml')\n",
    "root= tree.getroot()\n",
    "data_chunks= chunckify(root, 50)\n",
    "mapped= list(map(mapper, data_chunks))\n",
    "mapped= list(filter(None, mapped))\n",
    "reduced= reduce(reducir_contadores, mapped)\n",
    "top_10_2= calcular_top_10(reduced)\n",
    "\n",
    "#print(top_10)\n",
    "\n",
    "#In order to execute the script, remove the # before the print function above.\n",
    "\n",
    "#The following lines we'll get the .txt with the requirements needed, in order to be read.\n",
    "with open(('/home/fer/OT301-python/bigdata/outputs/GC_r2.txt'), 'w') as f:\n",
    "        f.write(str(top_10_2))                   \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OwnerUser_Id</th>\n",
       "      <th>FavoriteCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>810</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137077</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133260</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>133875</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13018</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131377</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>133733</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2644</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>139547</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>146097</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OwnerUser_Id FavoriteCount\n",
       "0          810             9\n",
       "1       137077             9\n",
       "2       133260             9\n",
       "3       133875             9\n",
       "4        13018             8\n",
       "5       131377             8\n",
       "6       133733             8\n",
       "7         2644             8\n",
       "8       139547             8\n",
       "9       146097             8"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(('/home/fer/OT301-python/bigdata/outputs/GC_r2.csv'), 'w') as f:\n",
    "        f.write(str(top_10_2))\n",
    "        f.close()\n",
    "\n",
    "df = pd.DataFrame(top_10_2.items(), columns=['OwnerUser_Id', 'FavoriteCount'])\n",
    "df.to_csv('/home/fer/OT301-python/bigdata/outputs/GC_r2.csv', index=False)\n",
    "df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third requirement: Relationship in between quantity of words in a post, and amount of answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from functools import reduce\n",
    "from typing import Counter\n",
    "import re\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "    \n",
    "def chunckify(iterable, len_of_chunk):\n",
    "    for i in range(0, len(iterable), len_of_chunk):\n",
    "        yield iterable[i:i + len_of_chunk]\n",
    "\n",
    "\n",
    "def obtener_rtas_aceptadas(data):\n",
    "    try:\n",
    "        comments= data.attrib['CommentCount']\n",
    "    except:\n",
    "        return\n",
    "    body= data.attrib['Body']\n",
    "    body= re.findall('(?<!\\S)[A-Za-z]+(?!\\S)|(?<!\\S)[A-Za-z]+(?=:(?!|S))', body)\n",
    "    len_comments = len(body)\n",
    "    return comments, len_comments \n",
    "\n",
    "\n",
    "def reducir_contadores(data1, data2):\n",
    "    return data1 + data2 \n",
    "\n",
    "\n",
    "def mapper(data):\n",
    "    palabras_mapeadas= list(map(obtener_rtas_aceptadas, data))\n",
    "    palabras_mapeadas= list(filter(None, palabras_mapeadas))\n",
    "    try:\n",
    "        reducido= reduce(reducir_contadores, palabras_mapeadas)\n",
    "    except:\n",
    "        return\n",
    "    return reducido\n",
    "\n",
    "\n",
    "tree= ET.parse(r'/home/fer/OT301-python/Stack Overflow 11-2010/112010 Meta Stack Overflow/posts.xml')\n",
    "root= tree.getroot()\n",
    "data_chunks= chunckify(root, 50)\n",
    "mapped= list(map(mapper, data_chunks))\n",
    "mapped= list(filter(None, mapped))\n",
    "reduced= reduce(reducir_contadores, mapped)\n",
    "\n",
    "\n",
    "#print(reduced)\n",
    "\n",
    "#In order to execute the script, remove the # before the print function above.\n",
    "\n",
    "#The following lines we'll get the .txt with the requirements needed, in order to be read.\n",
    "with open(('/home/fer/OT301-python/bigdata/outputs/GC_r3.txt'), 'w') as f:\n",
    "        f.write(str(reduced))                   \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(('/home/fer/OT301-python/bigdata/outputs/GC_r3.csv'), 'w') as f:\n",
    "        f.write(str(top_10_2))\n",
    "        f.close()\n",
    "\n",
    "df = pd.DataFrame(top_10_2.items(), columns=['Cantidad_Respuestas', 'Cantidad_palabras'])\n",
    "df.to_csv('/home/fer/OT301-python/bigdata/outputs/GC_r3.csv', index=False)\n",
    "df.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
